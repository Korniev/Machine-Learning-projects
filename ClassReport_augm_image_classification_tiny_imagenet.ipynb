{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Korniev/Machine-Learning-projects/blob/main/ClassReport_augm_image_classification_tiny_imagenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries:"
      ],
      "metadata": {
        "id": "y05ocGn0L1PH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vsXqvlafahrb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "import zipfile\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the file to Google Colab and list the uploaded files to verify:"
      ],
      "metadata": {
        "id": "E_qkMY2jLVQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f'Uploaded file: {filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "oU_LK7xfLbi2",
        "outputId": "905e30d1-6c21-4cd5-fcb9-8f87a284b0fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-27a7209a-ec21-4aa8-b1ee-4cca837b2217\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-27a7209a-ec21-4aa8-b1ee-4cca837b2217\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving archive.zip to archive.zip\n",
            "Uploaded file: archive.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the uploaded file and Assuming the uploaded file is named 'archive.zip':"
      ],
      "metadata": {
        "id": "_ljtApXuLgCz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NUzlU1e3ajHo"
      },
      "outputs": [],
      "source": [
        "zip_path = '/content/archive.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the extracted files:"
      ],
      "metadata": {
        "id": "chUx-M6RLvhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/tiny-imagenet-200"
      ],
      "metadata": {
        "id": "e0seJOsRLyMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b4a952-8e33-448e-c781-ca94b557d400"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make some manipulations for dataset"
      ],
      "metadata": {
        "id": "9cYq6UV4L_8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dir = '/content/tiny-imagenet-200/val'\n",
        "val_images_dir = os.path.join(val_dir, 'images')\n",
        "val_annotations_file = os.path.join(val_dir, 'val_annotations.txt')\n"
      ],
      "metadata": {
        "id": "ejLbTZg5V1s7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create subdirectories for each class and then remove the now-empty images directory:"
      ],
      "metadata": {
        "id": "EcDznjxSMD33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(val_annotations_file, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        parts = line.strip().split('\\t')\n",
        "        image_name = parts[0]\n",
        "        class_name = parts[1]\n",
        "\n",
        "        class_dir = os.path.join(val_dir, class_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            os.makedirs(class_dir)\n",
        "\n",
        "        source = os.path.join(val_images_dir, image_name)\n",
        "        destination = os.path.join(class_dir, image_name)\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "shutil.rmtree(val_images_dir)"
      ],
      "metadata": {
        "id": "9ur8CNJxMHsT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define paths:"
      ],
      "metadata": {
        "id": "m8ipZAN9MMmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = './tiny-imagenet-200/train'\n",
        "val_dir = './tiny-imagenet-200/val'"
      ],
      "metadata": {
        "id": "G7A7HGEfMSYN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define image data generators with enhanced data augmentation:"
      ],
      "metadata": {
        "id": "ah7gOHIJMTHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Uvd_ctwJXSZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f4ab68-fd7c-4616-c90b-fcdee5329555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pre-trained EfficientNetB3 model:"
      ],
      "metadata": {
        "id": "py7CcYNrMZOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(64, 64, 3))"
      ],
      "metadata": {
        "id": "nicpepKrMbZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f54a30-006f-4c97-c68f-d97a0445b437"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add custom layers on top:"
      ],
      "metadata": {
        "id": "pzLKm8AxMg30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(200, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "311Zj-sOMnDb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune the entire model by unfreeze the last 100 layers:"
      ],
      "metadata": {
        "id": "zaD3bRTkMnj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[-100:]:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "ZI-Svz-nMvVl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model:"
      ],
      "metadata": {
        "id": "Ena8yWCKMxYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ahr9j6_JMzVR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a learning rate scheduler and callbacks:"
      ],
      "metadata": {
        "id": "UlmpLfptM2N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.000001)"
      ],
      "metadata": {
        "id": "2oUKgJOxM5RR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model:"
      ],
      "metadata": {
        "id": "SeqM21u6M9y4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "j7Np_5TyXoGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b8e0a5-27ae-48b0-eb27-1b4f00f857a9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 85ms/step - accuracy: 0.0464 - loss: 15.4556 - val_accuracy: 0.3278 - val_loss: 7.1360 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 82ms/step - accuracy: 0.2401 - loss: 6.7960 - val_accuracy: 0.4305 - val_loss: 3.9924 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 80ms/step - accuracy: 0.3413 - loss: 4.1173 - val_accuracy: 0.4728 - val_loss: 3.0772 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 82ms/step - accuracy: 0.3887 - loss: 3.2824 - val_accuracy: 0.4950 - val_loss: 2.7391 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 80ms/step - accuracy: 0.4283 - loss: 2.9064 - val_accuracy: 0.5097 - val_loss: 2.6449 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 84ms/step - accuracy: 0.4496 - loss: 2.7235 - val_accuracy: 0.5190 - val_loss: 2.5658 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 81ms/step - accuracy: 0.4755 - loss: 2.5728 - val_accuracy: 0.5273 - val_loss: 2.5037 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 82ms/step - accuracy: 0.4930 - loss: 2.4732 - val_accuracy: 0.5355 - val_loss: 2.4593 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 80ms/step - accuracy: 0.5067 - loss: 2.3760 - val_accuracy: 0.5409 - val_loss: 2.4289 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 82ms/step - accuracy: 0.5227 - loss: 2.2903 - val_accuracy: 0.5479 - val_loss: 2.3898 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 79ms/step - accuracy: 0.5380 - loss: 2.1968 - val_accuracy: 0.5469 - val_loss: 2.3722 - learning_rate: 9.0484e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 79ms/step - accuracy: 0.5544 - loss: 2.1114 - val_accuracy: 0.5510 - val_loss: 2.3351 - learning_rate: 8.1873e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 80ms/step - accuracy: 0.5698 - loss: 1.9999 - val_accuracy: 0.5641 - val_loss: 2.2378 - learning_rate: 7.4082e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 78ms/step - accuracy: 0.5805 - loss: 1.9263 - val_accuracy: 0.5574 - val_loss: 2.2627 - learning_rate: 6.7032e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 79ms/step - accuracy: 0.5919 - loss: 1.8505 - val_accuracy: 0.5694 - val_loss: 2.1492 - learning_rate: 6.0653e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 79ms/step - accuracy: 0.6045 - loss: 1.7854 - val_accuracy: 0.5694 - val_loss: 2.1805 - learning_rate: 5.4881e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 78ms/step - accuracy: 0.6162 - loss: 1.7158 - val_accuracy: 0.5670 - val_loss: 2.1845 - learning_rate: 4.9659e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 79ms/step - accuracy: 0.6234 - loss: 1.6642 - val_accuracy: 0.5705 - val_loss: 2.1345 - learning_rate: 4.4933e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 78ms/step - accuracy: 0.6333 - loss: 1.6133 - val_accuracy: 0.5744 - val_loss: 2.0994 - learning_rate: 4.0657e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 77ms/step - accuracy: 0.6401 - loss: 1.5709 - val_accuracy: 0.5807 - val_loss: 2.0617 - learning_rate: 3.6788e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 78ms/step - accuracy: 0.6536 - loss: 1.5124 - val_accuracy: 0.5786 - val_loss: 2.0850 - learning_rate: 3.3287e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 78ms/step - accuracy: 0.6551 - loss: 1.4923 - val_accuracy: 0.5753 - val_loss: 2.1198 - learning_rate: 3.0119e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 77ms/step - accuracy: 0.6631 - loss: 1.4526 - val_accuracy: 0.5764 - val_loss: 2.0768 - learning_rate: 2.7253e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 77ms/step - accuracy: 0.6647 - loss: 1.4193 - val_accuracy: 0.5773 - val_loss: 2.0708 - learning_rate: 4.9319e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 80ms/step - accuracy: 0.6741 - loss: 1.3786 - val_accuracy: 0.5797 - val_loss: 2.0580 - learning_rate: 4.4626e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 78ms/step - accuracy: 0.6855 - loss: 1.3315 - val_accuracy: 0.5813 - val_loss: 2.0490 - learning_rate: 4.0379e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 78ms/step - accuracy: 0.6882 - loss: 1.3212 - val_accuracy: 0.5796 - val_loss: 2.0537 - learning_rate: 3.6537e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 77ms/step - accuracy: 0.6875 - loss: 1.3088 - val_accuracy: 0.5803 - val_loss: 2.0521 - learning_rate: 3.3060e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 78ms/step - accuracy: 0.6899 - loss: 1.3022 - val_accuracy: 0.5779 - val_loss: 2.0608 - learning_rate: 2.9914e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 77ms/step - accuracy: 0.6907 - loss: 1.2924 - val_accuracy: 0.5793 - val_loss: 2.0563 - learning_rate: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, reduce_lr, lr_scheduler]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate the model:"
      ],
      "metadata": {
        "id": "5KGI7a7XNBm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "id": "TnCZp18Hn69J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8399274-3e66-48e6-eb9b-2cab020e15f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 0.5796 - loss: 2.0800\n",
            "Validation Accuracy: 0.5813000202178955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's visualize prediction:**"
      ],
      "metadata": {
        "id": "Oxb-ef1XNIeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "JVmBg5DINMSM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from synset IDs to human-readable labels\n",
        "def load_class_labels(filepath):\n",
        "    class_labels = {}\n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split('\\t')\n",
        "            synset_id = parts[0]\n",
        "            label = parts[1]\n",
        "            class_labels[synset_id] = label\n",
        "    return class_labels\n",
        "\n",
        "class_labels = load_class_labels('/content/tiny-imagenet-200/words.txt')\n"
      ],
      "metadata": {
        "id": "0vtXbzpP9DoB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to load, preprocess, and predict an image:"
      ],
      "metadata": {
        "id": "jixtCpPkNOWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_visualize(image_path, model, class_indices, class_labels):\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, target_size=(64, 64))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "    # Decode the prediction\n",
        "    class_labels_reverse = {v: k for k, v in class_indices.items()}\n",
        "    predicted_synset_id = class_labels_reverse[predicted_class_index]\n",
        "    predicted_class_label = class_labels[predicted_synset_id]\n",
        "\n",
        "    # Print prediction probabilities for debugging\n",
        "    print(f\"Predictions: {predictions}\")\n",
        "    print(f\"Predicted class index: {predicted_class_index}\")\n",
        "    print(f\"Predicted synset ID: {predicted_synset_id}\")\n",
        "    print(f\"Predicted class label: {predicted_class_label}\")\n",
        "\n",
        "    # Visualize the result\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'Predicted: {predicted_class_label} (Class {predicted_class_index})')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fMIPDG6e9R5E"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume 'class_indices' is a dictionary mapping class names to their index:"
      ],
      "metadata": {
        "id": "2GipmwXYNSuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = train_generator.class_indices"
      ],
      "metadata": {
        "id": "QIYwRQCuNTi_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the function with an example image:"
      ],
      "metadata": {
        "id": "oZnwFgylNWiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_visualize('/content/1.png', model, class_indices, class_labels)"
      ],
      "metadata": {
        "id": "eVdoA48TNaI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97f0d79d-0626-47dd-e00d-92b73228654d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
            "Predictions: [[0.00461535 0.00445463 0.00244321 0.00607749 0.00679161 0.00494206\n",
            "  0.00351348 0.00658765 0.002254   0.00554549 0.00656884 0.00375904\n",
            "  0.00420156 0.00431979 0.00696166 0.00841614 0.00727544 0.00444519\n",
            "  0.00560328 0.00359648 0.00425274 0.0060259  0.0049207  0.00929257\n",
            "  0.00539108 0.00416506 0.00490678 0.00565874 0.00495369 0.0042571\n",
            "  0.00385838 0.00601738 0.00610546 0.0036484  0.00349594 0.00407618\n",
            "  0.00520231 0.00577632 0.00499986 0.00747732 0.00596848 0.00478922\n",
            "  0.00454524 0.00348378 0.00352593 0.00435942 0.00548556 0.00393524\n",
            "  0.00352157 0.00618018 0.00504331 0.00419932 0.00488107 0.00437323\n",
            "  0.00491648 0.00383361 0.00434589 0.00493827 0.00574497 0.00362222\n",
            "  0.00446061 0.00433168 0.00335864 0.00544969 0.00370858 0.00501509\n",
            "  0.00631976 0.00592712 0.00564635 0.00661959 0.00492685 0.00813254\n",
            "  0.00403024 0.00388272 0.00519947 0.00615624 0.0044028  0.00609878\n",
            "  0.0048124  0.00364653 0.00642113 0.00533551 0.00458061 0.00459459\n",
            "  0.00456464 0.00546926 0.00447591 0.00764183 0.00606196 0.00476636\n",
            "  0.00378574 0.00905505 0.00513091 0.0036471  0.00562313 0.00426891\n",
            "  0.00516965 0.00476009 0.0061381  0.00510795 0.00399023 0.00543462\n",
            "  0.00728016 0.00609018 0.00473412 0.00266679 0.00567869 0.00614366\n",
            "  0.00693833 0.00354983 0.00426419 0.00642771 0.00548433 0.00438995\n",
            "  0.00478429 0.00322692 0.0045444  0.00378964 0.00393446 0.00450353\n",
            "  0.00422153 0.00417733 0.00339767 0.00690522 0.00491303 0.00510512\n",
            "  0.00507976 0.0041563  0.00320567 0.00371442 0.00459201 0.00613326\n",
            "  0.00478145 0.00394709 0.00636931 0.00736636 0.00437342 0.00393739\n",
            "  0.00577474 0.00455841 0.00448368 0.00669474 0.00558557 0.00585439\n",
            "  0.00847397 0.00528172 0.00285222 0.00622423 0.00381512 0.00846577\n",
            "  0.00428299 0.00348097 0.0058729  0.0027631  0.0048163  0.00518843\n",
            "  0.00327333 0.00534096 0.00278546 0.00347206 0.00388374 0.00630893\n",
            "  0.00382797 0.0056848  0.00405266 0.00586518 0.00628393 0.00615674\n",
            "  0.00253604 0.00324999 0.00690636 0.00453998 0.00353361 0.00585903\n",
            "  0.00503939 0.00556158 0.00345729 0.00328803 0.00512778 0.00524342\n",
            "  0.00469413 0.00590646 0.00509949 0.00553028 0.00473305 0.00506668\n",
            "  0.00535584 0.00460164 0.00546879 0.00417316 0.00344914 0.00577244\n",
            "  0.00430116 0.00874051 0.00524698 0.004723   0.00479456 0.00529213\n",
            "  0.00553622 0.00426312]]\n",
            "Predicted class index: 23\n",
            "Predicted synset ID: n02074367\n",
            "Predicted class label: dugong, Dugong dugon\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get true labels and predicted labels for the validation set"
      ],
      "metadata": {
        "id": "OqD8krZN_-9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for images, labels in val_generator:\n",
        "    predictions = model.predict(images)\n",
        "    predicted_labels.extend(np.argmax(predictions, axis=1))\n",
        "    true_labels.extend(np.argmax(labels, axis=1))\n",
        "    if len(true_labels) >= val_generator.samples:\n",
        "        break\n",
        "\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzs7nLDa__Uc",
        "outputId": "1a5b3f4f-0ed7-4aca-999e-931bb284717f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the classification report"
      ],
      "metadata": {
        "id": "nmp-vxhuAHzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "E6gudX6tAQWT"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(true_labels, predicted_labels, target_names=list(class_indices.keys()))\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF8p22UaAIM7",
        "outputId": "b4aefd7b-fc87-47fe-86a8-51dbe02f0ec7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   n01443537       0.00      0.00      0.00        50\n",
            "   n01629819       0.00      0.00      0.00        50\n",
            "   n01641577       0.00      0.00      0.00        50\n",
            "   n01644900       0.00      0.00      0.00        50\n",
            "   n01698640       0.00      0.00      0.00        50\n",
            "   n01742172       0.00      0.00      0.00        50\n",
            "   n01768244       0.00      0.00      0.00        50\n",
            "   n01770393       0.00      0.00      0.00        50\n",
            "   n01774384       0.00      0.00      0.00        50\n",
            "   n01774750       0.00      0.00      0.00        50\n",
            "   n01784675       0.00      0.00      0.00        50\n",
            "   n01855672       0.00      0.00      0.00        50\n",
            "   n01882714       0.00      0.00      0.00        50\n",
            "   n01910747       0.00      0.00      0.00        50\n",
            "   n01917289       0.00      0.00      0.00        50\n",
            "   n01944390       0.00      0.00      0.00        50\n",
            "   n01945685       0.00      0.00      0.00        50\n",
            "   n01950731       0.00      0.00      0.00        50\n",
            "   n01983481       0.00      0.00      0.00        50\n",
            "   n01984695       0.00      0.00      0.00        50\n",
            "   n02002724       0.00      0.00      0.00        50\n",
            "   n02056570       0.00      0.00      0.00        50\n",
            "   n02058221       0.00      0.00      0.00        50\n",
            "   n02074367       0.00      0.00      0.00        50\n",
            "   n02085620       0.00      0.00      0.00        50\n",
            "   n02094433       0.00      0.00      0.00        50\n",
            "   n02099601       0.00      0.00      0.00        50\n",
            "   n02099712       0.00      0.00      0.00        50\n",
            "   n02106662       0.00      0.00      0.00        50\n",
            "   n02113799       0.00      0.00      0.00        50\n",
            "   n02123045       0.00      0.00      0.00        50\n",
            "   n02123394       0.00      0.00      0.00        50\n",
            "   n02124075       0.00      0.00      0.00        50\n",
            "   n02125311       0.00      0.00      0.00        50\n",
            "   n02129165       0.00      0.00      0.00        50\n",
            "   n02132136       0.00      0.00      0.00        50\n",
            "   n02165456       0.00      0.00      0.00        50\n",
            "   n02190166       0.00      0.00      0.00        50\n",
            "   n02206856       0.00      0.00      0.00        50\n",
            "   n02226429       0.00      0.00      0.00        50\n",
            "   n02231487       0.00      0.00      0.00        50\n",
            "   n02233338       0.00      0.00      0.00        50\n",
            "   n02236044       0.00      0.00      0.00        50\n",
            "   n02268443       0.00      0.00      0.00        50\n",
            "   n02279972       0.00      0.00      0.00        50\n",
            "   n02281406       0.00      0.00      0.00        50\n",
            "   n02321529       0.00      0.00      0.00        50\n",
            "   n02364673       0.00      0.00      0.00        50\n",
            "   n02395406       0.00      0.00      0.00        50\n",
            "   n02403003       0.00      0.00      0.00        50\n",
            "   n02410509       0.00      0.00      0.00        50\n",
            "   n02415577       0.00      0.00      0.00        50\n",
            "   n02423022       0.00      0.00      0.00        50\n",
            "   n02437312       0.00      0.00      0.00        50\n",
            "   n02480495       0.00      0.00      0.00        50\n",
            "   n02481823       0.00      0.00      0.00        50\n",
            "   n02486410       0.00      0.00      0.00        50\n",
            "   n02504458       0.00      0.00      0.00        50\n",
            "   n02509815       0.00      0.00      0.00        50\n",
            "   n02666196       0.00      0.00      0.00        50\n",
            "   n02669723       0.00      0.00      0.00        50\n",
            "   n02699494       0.00      0.00      0.00        50\n",
            "   n02730930       0.00      0.00      0.00        50\n",
            "   n02769748       0.00      0.00      0.00        50\n",
            "   n02788148       0.00      0.00      0.00        50\n",
            "   n02791270       0.00      0.00      0.00        50\n",
            "   n02793495       0.00      0.00      0.00        50\n",
            "   n02795169       0.00      0.00      0.00        50\n",
            "   n02802426       0.00      0.00      0.00        50\n",
            "   n02808440       0.00      0.00      0.00        50\n",
            "   n02814533       0.00      0.00      0.00        50\n",
            "   n02814860       0.00      0.00      0.00        50\n",
            "   n02815834       0.00      0.00      0.00        50\n",
            "   n02823428       0.00      0.00      0.00        50\n",
            "   n02837789       0.00      0.00      0.00        50\n",
            "   n02841315       0.00      0.00      0.00        50\n",
            "   n02843684       0.00      0.00      0.00        50\n",
            "   n02883205       0.00      0.00      0.00        50\n",
            "   n02892201       0.00      0.00      0.00        50\n",
            "   n02906734       0.00      0.00      0.00        50\n",
            "   n02909870       0.00      0.00      0.00        50\n",
            "   n02917067       0.00      0.00      0.00        50\n",
            "   n02927161       0.00      0.00      0.00        50\n",
            "   n02948072       0.00      0.00      0.00        50\n",
            "   n02950826       0.00      0.00      0.00        50\n",
            "   n02963159       0.00      0.00      0.00        50\n",
            "   n02977058       0.00      0.00      0.00        50\n",
            "   n02988304       0.00      0.00      0.00        50\n",
            "   n02999410       0.00      0.00      0.00        50\n",
            "   n03014705       0.00      0.00      0.00        50\n",
            "   n03026506       0.00      0.00      0.00        50\n",
            "   n03042490       0.00      0.00      0.00        50\n",
            "   n03085013       0.00      0.00      0.00        50\n",
            "   n03089624       0.00      0.00      0.00        50\n",
            "   n03100240       0.00      0.00      0.00        50\n",
            "   n03126707       0.00      0.00      0.00        50\n",
            "   n03160309       0.00      0.00      0.00        50\n",
            "   n03179701       0.00      0.00      0.00        50\n",
            "   n03201208       0.00      0.00      0.00        50\n",
            "   n03250847       0.00      0.00      0.00        50\n",
            "   n03255030       0.00      0.00      0.00        50\n",
            "   n03355925       0.00      0.00      0.00        50\n",
            "   n03388043       0.00      0.00      0.00        50\n",
            "   n03393912       0.00      0.00      0.00        50\n",
            "   n03400231       0.00      0.00      0.00        50\n",
            "   n03404251       0.00      0.00      0.00        50\n",
            "   n03424325       0.00      0.00      0.00        50\n",
            "   n03444034       0.00      0.00      0.00        50\n",
            "   n03447447       0.00      0.00      0.00        50\n",
            "   n03544143       0.00      0.00      0.00        50\n",
            "   n03584254       0.00      0.00      0.00        50\n",
            "   n03599486       0.00      0.00      0.00        50\n",
            "   n03617480       0.00      0.00      0.00        50\n",
            "   n03637318       0.00      0.00      0.00        50\n",
            "   n03649909       0.00      0.00      0.00        50\n",
            "   n03662601       0.00      0.00      0.00        50\n",
            "   n03670208       0.00      0.00      0.00        50\n",
            "   n03706229       0.00      0.00      0.00        50\n",
            "   n03733131       0.00      0.00      0.00        50\n",
            "   n03763968       0.00      0.00      0.00        50\n",
            "   n03770439       0.00      0.00      0.00        50\n",
            "   n03796401       0.00      0.00      0.00        50\n",
            "   n03804744       0.00      0.00      0.00        50\n",
            "   n03814639       0.00      0.00      0.00        50\n",
            "   n03837869       0.00      0.00      0.00        50\n",
            "   n03838899       0.00      0.00      0.00        50\n",
            "   n03854065       0.00      0.00      0.00        50\n",
            "   n03891332       0.00      0.00      0.00        50\n",
            "   n03902125       0.00      0.00      0.00        50\n",
            "   n03930313       0.00      0.00      0.00        50\n",
            "   n03937543       0.00      0.00      0.00        50\n",
            "   n03970156       0.00      0.00      0.00        50\n",
            "   n03976657       0.00      0.00      0.00        50\n",
            "   n03977966       0.00      0.00      0.00        50\n",
            "   n03980874       0.00      0.00      0.00        50\n",
            "   n03983396       0.00      0.00      0.00        50\n",
            "   n03992509       0.00      0.00      0.00        50\n",
            "   n04008634       0.00      0.00      0.00        50\n",
            "   n04023962       0.00      0.00      0.00        50\n",
            "   n04067472       0.00      0.00      0.00        50\n",
            "   n04070727       0.00      0.00      0.00        50\n",
            "   n04074963       0.00      0.00      0.00        50\n",
            "   n04099969       0.00      0.00      0.00        50\n",
            "   n04118538       0.00      0.00      0.00        50\n",
            "   n04133789       0.00      0.00      0.00        50\n",
            "   n04146614       0.00      0.00      0.00        50\n",
            "   n04149813       0.00      0.00      0.00        50\n",
            "   n04179913       0.00      0.00      0.00        50\n",
            "   n04251144       0.00      0.00      0.00        50\n",
            "   n04254777       0.00      0.00      0.00        50\n",
            "   n04259630       0.00      0.00      0.00        50\n",
            "   n04265275       0.00      0.00      0.00        50\n",
            "   n04275548       0.00      0.00      0.00        50\n",
            "   n04285008       0.00      0.00      0.00        50\n",
            "   n04311004       0.00      0.00      0.00        50\n",
            "   n04328186       0.00      0.00      0.00        50\n",
            "   n04356056       0.00      0.00      0.00        50\n",
            "   n04366367       0.00      0.00      0.00        50\n",
            "   n04371430       0.00      0.00      0.00        50\n",
            "   n04376876       0.00      0.00      0.00        50\n",
            "   n04398044       0.00      0.00      0.00        50\n",
            "   n04399382       0.00      0.00      0.00        50\n",
            "   n04417672       0.00      0.00      0.00        50\n",
            "   n04456115       0.00      0.00      0.00        50\n",
            "   n04465501       0.00      0.00      0.00        50\n",
            "   n04486054       0.00      0.00      0.00        50\n",
            "   n04487081       0.00      0.00      0.00        50\n",
            "   n04501370       0.00      0.00      0.00        50\n",
            "   n04507155       0.00      0.00      0.00        50\n",
            "   n04532106       0.00      0.00      0.00        50\n",
            "   n04532670       0.00      0.00      0.00        50\n",
            "   n04540053       0.00      0.00      0.00        50\n",
            "   n04560804       0.00      0.00      0.00        50\n",
            "   n04562935       0.00      0.00      0.00        50\n",
            "   n04596742       0.00      0.00      0.00        50\n",
            "   n04597913       0.00      0.00      0.00        50\n",
            "   n06596364       0.00      0.00      0.00        50\n",
            "   n07579787       0.00      0.00      0.00        50\n",
            "   n07583066       0.00      0.00      0.00        50\n",
            "   n07614500       0.00      0.00      0.00        50\n",
            "   n07615774       0.00      0.00      0.00        50\n",
            "   n07695742       0.00      0.00      0.00        50\n",
            "   n07711569       0.00      0.00      0.00        50\n",
            "   n07715103       0.00      0.00      0.00        50\n",
            "   n07720875       0.00      0.00      0.00        50\n",
            "   n07734744       0.00      0.00      0.00        50\n",
            "   n07747607       0.00      0.00      0.00        50\n",
            "   n07749582       0.00      0.00      0.00        50\n",
            "   n07753592       0.00      0.00      0.00        50\n",
            "   n07768694       0.00      0.00      0.00        50\n",
            "   n07871810       0.00      0.00      0.00        50\n",
            "   n07873807       0.00      0.00      0.00        50\n",
            "   n07875152       0.00      0.00      0.00        50\n",
            "   n07920052       0.01      1.00      0.01        50\n",
            "   n09193705       0.00      0.00      0.00        50\n",
            "   n09246464       0.00      0.00      0.00        50\n",
            "   n09256479       0.00      0.00      0.00        50\n",
            "   n09332890       0.00      0.00      0.00        50\n",
            "   n09428293       0.00      0.00      0.00        50\n",
            "   n12267677       0.00      0.00      0.00        50\n",
            "\n",
            "    accuracy                           0.01     10000\n",
            "   macro avg       0.00      0.01      0.00     10000\n",
            "weighted avg       0.00      0.01      0.00     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the classification report, let’s assume identified classes with an F1-score lower than 0.50."
      ],
      "metadata": {
        "id": "yCslpgL5Ar3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume we have true_labels and predicted_labels from previous steps:"
      ],
      "metadata": {
        "id": "AjzEXsscDL6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report_dict = classification_report(true_labels, predicted_labels, target_names=list(class_indices.keys()), output_dict=True)"
      ],
      "metadata": {
        "id": "rMVadf0ZDNYG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify Poor Performing Classes:"
      ],
      "metadata": {
        "id": "Cdl4tJT5DTUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_poor_performing_classes(report_dict, threshold=0.5):\n",
        "    poor_classes = []\n",
        "    for class_name, metrics in report_dict.items():\n",
        "        if class_name not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
        "            if metrics[\"f1-score\"] < threshold:\n",
        "                poor_classes.append(class_name)\n",
        "    return poor_classes\n",
        "\n",
        "# Define the threshold for F1-score\n",
        "f1_threshold = 0.5\n",
        "\n",
        "# Get the list of poor performing classes\n",
        "poor_classes = get_poor_performing_classes(report_dict, f1_threshold)\n",
        "print(f\"Poor performing classes: {poor_classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAn6E9seDT5P",
        "outputId": "584b1604-92b2-4d56-b018-9f88def67041"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poor performing classes: ['n01742172', 'n02085620', 'n02123045', 'n02124075', 'n02403003', 'n02730930', 'n02788148', 'n02791270', 'n02795169', 'n02814533', 'n02906734', 'n02909870', 'n02948072', 'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03100240', 'n03126707', 'n03250847', 'n03255030', 'n03404251', 'n03424325', 'n03617480', 'n03637318', 'n03763968', 'n03770439', 'n03814639', 'n03838899', 'n03902125', 'n03970156', 'n03976657', 'n03983396', 'n04023962', 'n04067472', 'n04259630', 'n04275548', 'n04356056', 'n04371430', 'n04376876', 'n04501370', 'n04507155', 'n04532106', 'n04560804', 'n04597913', 'n06596364', 'n07579787', 'n07711569', 'n09246464', 'n09332890']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Different Augmentation Strategies Based on Class Performance:"
      ],
      "metadata": {
        "id": "ARpscegoDeLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create a separate data generator with more aggressive augmentations for these classes."
      ],
      "metadata": {
        "id": "5FJNrTKbA2c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "train_dir = './tiny-imagenet-200/train'\n",
        "val_dir = './tiny-imagenet-200/val'\n",
        "\n",
        "# Define image data generators with enhanced data augmentation\n",
        "normal_augmentation = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "aggressive_augmentation = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=60,\n",
        "    width_shift_range=0.5,\n",
        "    height_shift_range=0.5,\n",
        "    shear_range=0.5,\n",
        "    zoom_range=0.5,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "JVLvKJcnAylL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_augmented_generator(directory, poor_classes, batch_size, target_size):\n",
        "    normal_generator = normal_augmentation.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    aggressive_generators = []\n",
        "    for class_name in poor_classes:\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        generator = aggressive_augmentation.flow_from_directory(\n",
        "            directory,\n",
        "            classes=[class_name],  # Only include the specific class\n",
        "            target_size=target_size,\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            shuffle=True\n",
        "        )\n",
        "        aggressive_generators.append(generator)\n",
        "\n",
        "    return normal_generator, aggressive_generators"
      ],
      "metadata": {
        "id": "QFaTKFdlDo6k"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_generator, aggressive_generators = get_augmented_generator(train_dir, poor_classes, batch_size=32, target_size=(64, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlo_anI1HEiS",
        "outputId": "b5018a82-0cf3-41e5-ad8a-34fdd2abdabc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n",
            "Found 500 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine augmented generators into one:"
      ],
      "metadata": {
        "id": "1787KXa0HRDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combined_generator(normal_gen, aggressive_gens):\n",
        "    while True:\n",
        "        # Get a batch from the normal generator\n",
        "        normal_data, normal_labels = next(normal_gen)\n",
        "        yield normal_data, normal_labels\n",
        "\n",
        "        # Get batches from each aggressive generator\n",
        "        for gen in aggressive_gens:\n",
        "            try:\n",
        "                data, labels = next(gen)\n",
        "                yield data, labels\n",
        "            except StopIteration:\n",
        "                continue\n",
        "\n",
        "train_generator = combined_generator(normal_generator, aggressive_generators)"
      ],
      "metadata": {
        "id": "_coeK3AiHRrO"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation generator remains the same:"
      ],
      "metadata": {
        "id": "WTz03MLBHWIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JeqGsdBHWxA",
        "outputId": "28bda9ef-b4b3-44de-c6b1-8fd27af178eb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('Data batch shape:', data_batch.shape)\n",
        "    print('Labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3VzTpa0NQg2",
        "outputId": "c113d793-33f0-4c63-90e0-3222e46d3e0d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data batch shape: (32, 64, 64, 3)\n",
            "Labels batch shape: (32, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can retrain the Model:"
      ],
      "metadata": {
        "id": "Smm0IydPD6cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the EfficientNetB3 base model\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(200, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Fine-tune the last 100 layers of the base model\n",
        "for layer in base_model.layers[-100:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compile the model with a standard learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "h0oADG2ROKMz"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the learning rate scheduler\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.000001)"
      ],
      "metadata": {
        "id": "2EpgGdJTD9PX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate steps per epoch:"
      ],
      "metadata": {
        "id": "2hTsFSC4O1pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(normal_generator) + sum(len(gen) for gen in aggressive_generators)"
      ],
      "metadata": {
        "id": "EGUuNlivO2Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue with trained model:"
      ],
      "metadata": {
        "id": "qF35Rs5jD6Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    callbacks=[early_stopping, reduce_lr, lr_scheduler]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "17raWYzbFck5",
        "outputId": "5719be20-88d2-4161-fcf5-2af73a563229"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 200)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-df8b487f524e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_generator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maggressive_generators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0;34m\"Arguments `target` and `output` must have the same shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;34m\"Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 200)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "2ITcrt1OD6XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "id": "GrUtIxWOFiYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D8G3XDqAM41N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7lS7AzsqD6Ps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5XTp2xyOD6FC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also we can adjust the class weights to give more importance to the poor performing classes:"
      ],
      "metadata": {
        "id": "NupfYawpBauO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(true_labels),\n",
        "    y=true_labels\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Compile the model with class weights\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping, reduce_lr, lr_scheduler]\n",
        ")\n"
      ],
      "metadata": {
        "id": "BTV6i3hEBdLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1We18bnTQ+oUBjGKbZT3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}