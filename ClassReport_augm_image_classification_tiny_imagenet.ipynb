{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Korniev/Machine-Learning-projects/blob/main/ClassReport_augm_image_classification_tiny_imagenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries:"
      ],
      "metadata": {
        "id": "y05ocGn0L1PH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vsXqvlafahrb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "import zipfile\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the uploaded file and Assuming the uploaded file is named 'archive.zip':"
      ],
      "metadata": {
        "id": "_ljtApXuLgCz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NUzlU1e3ajHo"
      },
      "outputs": [],
      "source": [
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/archive.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the extracted files:"
      ],
      "metadata": {
        "id": "chUx-M6RLvhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/tiny-imagenet-200"
      ],
      "metadata": {
        "id": "e0seJOsRLyMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f504af5-2d0a-4787-8c13-096f07b5d890"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make some manipulations for dataset"
      ],
      "metadata": {
        "id": "9cYq6UV4L_8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dir = '/content/tiny-imagenet-200/val'\n",
        "val_images_dir = os.path.join(val_dir, 'images')\n",
        "val_annotations_file = os.path.join(val_dir, 'val_annotations.txt')\n"
      ],
      "metadata": {
        "id": "ejLbTZg5V1s7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create subdirectories for each class and then remove the now-empty images directory:"
      ],
      "metadata": {
        "id": "EcDznjxSMD33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(val_annotations_file, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        parts = line.strip().split('\\t')\n",
        "        image_name = parts[0]\n",
        "        class_name = parts[1]\n",
        "\n",
        "        class_dir = os.path.join(val_dir, class_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            os.makedirs(class_dir)\n",
        "\n",
        "        source = os.path.join(val_images_dir, image_name)\n",
        "        destination = os.path.join(class_dir, image_name)\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "shutil.rmtree(val_images_dir)"
      ],
      "metadata": {
        "id": "9ur8CNJxMHsT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define paths:"
      ],
      "metadata": {
        "id": "m8ipZAN9MMmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = './tiny-imagenet-200/train'\n",
        "val_dir = './tiny-imagenet-200/val'"
      ],
      "metadata": {
        "id": "G7A7HGEfMSYN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define image data generators with enhanced data augmentation:"
      ],
      "metadata": {
        "id": "ah7gOHIJMTHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Uvd_ctwJXSZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f78f77-2c78-461a-c3a7-f99e5ee5b854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pre-trained EfficientNetB3 model:"
      ],
      "metadata": {
        "id": "py7CcYNrMZOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(64, 64, 3))"
      ],
      "metadata": {
        "id": "nicpepKrMbZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbd7dec-0a68-4e02-a931-f4b47515aa2c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add custom layers on top:"
      ],
      "metadata": {
        "id": "pzLKm8AxMg30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(200, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "311Zj-sOMnDb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune the entire model by unfreeze the last 100 layers:"
      ],
      "metadata": {
        "id": "zaD3bRTkMnj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[-100:]:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "ZI-Svz-nMvVl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model:"
      ],
      "metadata": {
        "id": "Ena8yWCKMxYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ahr9j6_JMzVR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a learning rate scheduler and callbacks:"
      ],
      "metadata": {
        "id": "UlmpLfptM2N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.000001)"
      ],
      "metadata": {
        "id": "2oUKgJOxM5RR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model:"
      ],
      "metadata": {
        "id": "SeqM21u6M9y4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "j7Np_5TyXoGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce60c24e-83be-4081-967b-ed9d052e17f0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 100ms/step - accuracy: 0.0429 - loss: 15.5289 - val_accuracy: 0.3165 - val_loss: 7.3152 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 83ms/step - accuracy: 0.2261 - loss: 6.9230 - val_accuracy: 0.4271 - val_loss: 4.0048 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 82ms/step - accuracy: 0.3335 - loss: 4.1787 - val_accuracy: 0.4677 - val_loss: 3.1157 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 83ms/step - accuracy: 0.3838 - loss: 3.3122 - val_accuracy: 0.4972 - val_loss: 2.7541 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 82ms/step - accuracy: 0.4189 - loss: 2.9473 - val_accuracy: 0.4761 - val_loss: 2.7866 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 82ms/step - accuracy: 0.4508 - loss: 2.7435 - val_accuracy: 0.5269 - val_loss: 2.5171 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 82ms/step - accuracy: 0.4675 - loss: 2.6121 - val_accuracy: 0.5341 - val_loss: 2.4915 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 83ms/step - accuracy: 0.4907 - loss: 2.4790 - val_accuracy: 0.5435 - val_loss: 2.4081 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 83ms/step - accuracy: 0.5049 - loss: 2.3960 - val_accuracy: 0.5368 - val_loss: 2.4173 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 83ms/step - accuracy: 0.5208 - loss: 2.3081 - val_accuracy: 0.5371 - val_loss: 2.4280 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 84ms/step - accuracy: 0.5352 - loss: 2.2173 - val_accuracy: 0.5472 - val_loss: 2.3838 - learning_rate: 9.0484e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 84ms/step - accuracy: 0.5498 - loss: 2.1175 - val_accuracy: 0.5626 - val_loss: 2.2372 - learning_rate: 8.1873e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 83ms/step - accuracy: 0.5670 - loss: 2.0172 - val_accuracy: 0.5745 - val_loss: 2.1849 - learning_rate: 7.4082e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 84ms/step - accuracy: 0.5781 - loss: 1.9407 - val_accuracy: 0.5660 - val_loss: 2.2160 - learning_rate: 6.7032e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 82ms/step - accuracy: 0.5925 - loss: 1.8625 - val_accuracy: 0.5638 - val_loss: 2.2452 - learning_rate: 6.0653e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 86ms/step - accuracy: 0.6042 - loss: 1.7905 - val_accuracy: 0.5604 - val_loss: 2.2004 - learning_rate: 5.4881e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 84ms/step - accuracy: 0.6112 - loss: 1.7304 - val_accuracy: 0.5755 - val_loss: 2.1238 - learning_rate: 4.9659e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 85ms/step - accuracy: 0.6264 - loss: 1.6683 - val_accuracy: 0.5706 - val_loss: 2.1394 - learning_rate: 4.4933e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 83ms/step - accuracy: 0.6319 - loss: 1.6221 - val_accuracy: 0.5745 - val_loss: 2.0978 - learning_rate: 4.0657e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 87ms/step - accuracy: 0.6379 - loss: 1.5844 - val_accuracy: 0.5707 - val_loss: 2.1144 - learning_rate: 3.6788e-05\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, reduce_lr, lr_scheduler]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate the model:"
      ],
      "metadata": {
        "id": "5KGI7a7XNBm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "id": "TnCZp18Hn69J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d40f1d3-77cd-4efa-ac36-cb1ddd02cee5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.5666 - loss: 2.1482\n",
            "Validation Accuracy: 0.5745000243186951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's visualize prediction:**"
      ],
      "metadata": {
        "id": "Oxb-ef1XNIeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "JVmBg5DINMSM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from synset IDs to human-readable labels\n",
        "def load_class_labels(filepath):\n",
        "    class_labels = {}\n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split('\\t')\n",
        "            synset_id = parts[0]\n",
        "            label = parts[1]\n",
        "            class_labels[synset_id] = label\n",
        "    return class_labels\n",
        "\n",
        "class_labels = load_class_labels('/content/tiny-imagenet-200/words.txt')\n"
      ],
      "metadata": {
        "id": "0vtXbzpP9DoB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to load, preprocess, and predict an image:"
      ],
      "metadata": {
        "id": "jixtCpPkNOWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_visualize(image_path, model, class_indices, class_labels):\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, target_size=(64, 64))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "    # Decode the prediction\n",
        "    class_labels_reverse = {v: k for k, v in class_indices.items()}\n",
        "    predicted_synset_id = class_labels_reverse[predicted_class_index]\n",
        "    predicted_class_label = class_labels[predicted_synset_id]\n",
        "\n",
        "    # Print prediction probabilities for debugging\n",
        "    print(f\"Predictions: {predictions}\")\n",
        "    print(f\"Predicted class index: {predicted_class_index}\")\n",
        "    print(f\"Predicted synset ID: {predicted_synset_id}\")\n",
        "    print(f\"Predicted class label: {predicted_class_label}\")\n",
        "\n",
        "    # Visualize the result\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'Predicted: {predicted_class_label} (Class {predicted_class_index})')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fMIPDG6e9R5E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume 'class_indices' is a dictionary mapping class names to their index:"
      ],
      "metadata": {
        "id": "2GipmwXYNSuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = train_generator.class_indices"
      ],
      "metadata": {
        "id": "QIYwRQCuNTi_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the function with an example image:"
      ],
      "metadata": {
        "id": "oZnwFgylNWiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_visualize('/content/1.png', model, class_indices, class_labels)"
      ],
      "metadata": {
        "id": "eVdoA48TNaI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "e6597787-49c8-4e3c-bb85-bbb595e3f97d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
            "Predictions: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Predicted class index: 46\n",
            "Predicted synset ID: n02321529\n",
            "Predicted class label: sea cucumber, holothurian\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get true labels and predicted labels for the validation set"
      ],
      "metadata": {
        "id": "OqD8krZN_-9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for images, labels in val_generator:\n",
        "    predictions = model.predict(images)\n",
        "    predicted_labels.extend(np.argmax(predictions, axis=1))\n",
        "    true_labels.extend(np.argmax(labels, axis=1))\n",
        "    if len(true_labels) >= val_generator.samples:\n",
        "        break\n",
        "\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzs7nLDa__Uc",
        "outputId": "783f143e-d6c9-496a-8d8c-baf05ef5834d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the classification report"
      ],
      "metadata": {
        "id": "nmp-vxhuAHzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "E6gudX6tAQWT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(true_labels, predicted_labels, target_names=list(class_indices.keys()))\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF8p22UaAIM7",
        "outputId": "1a783222-f7e9-4d14-be47-399916fdf59f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   n01443537       0.92      0.72      0.81        50\n",
            "   n01629819       0.83      0.70      0.76        50\n",
            "   n01641577       0.58      0.66      0.62        50\n",
            "   n01644900       0.61      0.34      0.44        50\n",
            "   n01698640       0.46      0.66      0.55        50\n",
            "   n01742172       0.30      0.46      0.37        50\n",
            "   n01768244       0.75      0.80      0.78        50\n",
            "   n01770393       0.68      0.34      0.45        50\n",
            "   n01774384       0.62      0.76      0.68        50\n",
            "   n01774750       0.70      0.52      0.60        50\n",
            "   n01784675       0.52      0.72      0.61        50\n",
            "   n01855672       0.74      0.58      0.65        50\n",
            "   n01882714       0.91      0.64      0.75        50\n",
            "   n01910747       0.86      0.74      0.80        50\n",
            "   n01917289       0.83      0.70      0.76        50\n",
            "   n01944390       0.72      0.52      0.60        50\n",
            "   n01945685       0.64      0.46      0.53        50\n",
            "   n01950731       0.79      0.68      0.73        50\n",
            "   n01983481       0.61      0.56      0.58        50\n",
            "   n01984695       0.68      0.64      0.66        50\n",
            "   n02002724       0.79      0.76      0.78        50\n",
            "   n02056570       0.84      0.74      0.79        50\n",
            "   n02058221       0.82      0.72      0.77        50\n",
            "   n02074367       0.90      0.76      0.83        50\n",
            "   n02085620       0.65      0.22      0.33        50\n",
            "   n02094433       0.92      0.66      0.77        50\n",
            "   n02099601       0.55      0.42      0.48        50\n",
            "   n02099712       0.55      0.44      0.49        50\n",
            "   n02106662       0.96      0.52      0.68        50\n",
            "   n02113799       0.54      0.44      0.48        50\n",
            "   n02123045       0.59      0.54      0.56        50\n",
            "   n02123394       0.91      0.58      0.71        50\n",
            "   n02124075       0.56      0.44      0.49        50\n",
            "   n02125311       0.61      0.56      0.58        50\n",
            "   n02129165       0.64      0.68      0.66        50\n",
            "   n02132136       0.55      0.66      0.60        50\n",
            "   n02165456       0.75      0.66      0.70        50\n",
            "   n02190166       0.69      0.66      0.67        50\n",
            "   n02206856       0.67      0.48      0.56        50\n",
            "   n02226429       0.48      0.72      0.58        50\n",
            "   n02231487       0.43      0.50      0.46        50\n",
            "   n02233338       0.43      0.54      0.48        50\n",
            "   n02236044       0.64      0.36      0.46        50\n",
            "   n02268443       0.51      0.50      0.51        50\n",
            "   n02279972       0.55      0.92      0.69        50\n",
            "   n02281406       0.81      0.84      0.82        50\n",
            "   n02321529       0.74      0.58      0.65        50\n",
            "   n02364673       0.76      0.58      0.66        50\n",
            "   n02395406       0.48      0.50      0.49        50\n",
            "   n02403003       0.55      0.44      0.49        50\n",
            "   n02410509       0.80      0.66      0.73        50\n",
            "   n02415577       0.50      0.64      0.56        50\n",
            "   n02423022       0.84      0.82      0.83        50\n",
            "   n02437312       0.69      0.58      0.63        50\n",
            "   n02480495       0.83      0.48      0.61        50\n",
            "   n02481823       0.72      0.68      0.70        50\n",
            "   n02486410       0.71      0.48      0.57        50\n",
            "   n02504458       0.65      0.72      0.69        50\n",
            "   n02509815       0.97      0.68      0.80        50\n",
            "   n02666196       0.60      0.56      0.58        50\n",
            "   n02669723       0.81      0.70      0.75        50\n",
            "   n02699494       0.44      0.64      0.52        50\n",
            "   n02730930       0.40      0.46      0.43        50\n",
            "   n02769748       0.59      0.54      0.56        50\n",
            "   n02788148       0.28      0.44      0.34        50\n",
            "   n02791270       0.27      0.30      0.29        50\n",
            "   n02793495       0.64      0.72      0.68        50\n",
            "   n02795169       0.46      0.44      0.45        50\n",
            "   n02802426       0.53      0.64      0.58        50\n",
            "   n02808440       0.63      0.48      0.55        50\n",
            "   n02814533       0.53      0.52      0.53        50\n",
            "   n02814860       0.80      0.66      0.73        50\n",
            "   n02815834       0.81      0.44      0.57        50\n",
            "   n02823428       0.47      0.70      0.56        50\n",
            "   n02837789       0.53      0.62      0.57        50\n",
            "   n02841315       0.55      0.54      0.55        50\n",
            "   n02843684       0.67      0.60      0.63        50\n",
            "   n02883205       0.35      0.28      0.31        50\n",
            "   n02892201       0.51      0.86      0.64        50\n",
            "   n02906734       0.45      0.40      0.43        50\n",
            "   n02909870       0.26      0.46      0.34        50\n",
            "   n02917067       0.78      0.86      0.82        50\n",
            "   n02927161       0.65      0.52      0.58        50\n",
            "   n02948072       0.75      0.36      0.49        50\n",
            "   n02950826       0.51      0.48      0.49        50\n",
            "   n02963159       0.64      0.46      0.53        50\n",
            "   n02977058       0.50      0.34      0.40        50\n",
            "   n02988304       0.61      0.46      0.52        50\n",
            "   n02999410       0.50      0.48      0.49        50\n",
            "   n03014705       0.60      0.74      0.66        50\n",
            "   n03026506       0.65      0.82      0.73        50\n",
            "   n03042490       0.76      0.62      0.68        50\n",
            "   n03085013       0.64      0.70      0.67        50\n",
            "   n03089624       0.52      0.58      0.55        50\n",
            "   n03100240       0.50      0.50      0.50        50\n",
            "   n03126707       0.51      0.52      0.51        50\n",
            "   n03160309       0.63      0.38      0.48        50\n",
            "   n03179701       0.57      0.56      0.57        50\n",
            "   n03201208       0.68      0.64      0.66        50\n",
            "   n03250847       0.42      0.42      0.42        50\n",
            "   n03255030       0.54      0.30      0.38        50\n",
            "   n03355925       0.60      0.68      0.64        50\n",
            "   n03388043       0.50      0.66      0.57        50\n",
            "   n03393912       0.78      0.70      0.74        50\n",
            "   n03400231       0.52      0.32      0.40        50\n",
            "   n03404251       0.76      0.32      0.45        50\n",
            "   n03424325       0.60      0.48      0.53        50\n",
            "   n03444034       0.75      0.76      0.75        50\n",
            "   n03447447       0.57      0.86      0.69        50\n",
            "   n03544143       0.80      0.64      0.71        50\n",
            "   n03584254       0.63      0.62      0.63        50\n",
            "   n03599486       0.45      0.74      0.56        50\n",
            "   n03617480       0.33      0.50      0.40        50\n",
            "   n03637318       0.31      0.74      0.44        50\n",
            "   n03649909       0.52      0.54      0.53        50\n",
            "   n03662601       0.81      0.84      0.82        50\n",
            "   n03670208       0.73      0.44      0.55        50\n",
            "   n03706229       0.59      0.60      0.59        50\n",
            "   n03733131       0.67      0.78      0.72        50\n",
            "   n03763968       0.28      0.42      0.33        50\n",
            "   n03770439       0.50      0.46      0.48        50\n",
            "   n03796401       0.79      0.44      0.56        50\n",
            "   n03804744       0.46      0.42      0.44        50\n",
            "   n03814639       0.59      0.44      0.51        50\n",
            "   n03837869       0.81      0.84      0.82        50\n",
            "   n03838899       0.42      0.56      0.48        50\n",
            "   n03854065       0.48      0.58      0.53        50\n",
            "   n03891332       0.64      0.64      0.64        50\n",
            "   n03902125       0.39      0.52      0.44        50\n",
            "   n03930313       0.58      0.76      0.66        50\n",
            "   n03937543       0.62      0.46      0.53        50\n",
            "   n03970156       0.42      0.16      0.23        50\n",
            "   n03976657       0.40      0.28      0.33        50\n",
            "   n03977966       0.74      0.68      0.71        50\n",
            "   n03980874       0.46      0.64      0.54        50\n",
            "   n03983396       0.45      0.30      0.36        50\n",
            "   n03992509       0.65      0.44      0.52        50\n",
            "   n04008634       0.51      0.48      0.49        50\n",
            "   n04023962       0.35      0.38      0.37        50\n",
            "   n04067472       0.45      0.34      0.39        50\n",
            "   n04070727       0.61      0.50      0.55        50\n",
            "   n04074963       0.65      0.62      0.63        50\n",
            "   n04099969       0.63      0.62      0.63        50\n",
            "   n04118538       0.76      0.70      0.73        50\n",
            "   n04133789       0.38      0.60      0.47        50\n",
            "   n04146614       0.70      0.92      0.79        50\n",
            "   n04149813       0.56      0.90      0.69        50\n",
            "   n04179913       0.67      0.44      0.53        50\n",
            "   n04251144       0.73      0.44      0.55        50\n",
            "   n04254777       0.56      0.62      0.59        50\n",
            "   n04259630       0.25      0.72      0.38        50\n",
            "   n04265275       0.46      0.48      0.47        50\n",
            "   n04275548       0.28      0.86      0.42        50\n",
            "   n04285008       0.59      0.72      0.65        50\n",
            "   n04311004       0.61      0.68      0.64        50\n",
            "   n04328186       0.49      0.62      0.55        50\n",
            "   n04356056       0.48      0.54      0.51        50\n",
            "   n04366367       0.37      0.74      0.50        50\n",
            "   n04371430       0.47      0.38      0.42        50\n",
            "   n04376876       0.39      0.18      0.25        50\n",
            "   n04398044       0.48      0.44      0.46        50\n",
            "   n04399382       0.77      0.54      0.64        50\n",
            "   n04417672       0.51      0.70      0.59        50\n",
            "   n04456115       0.74      0.52      0.61        50\n",
            "   n04465501       0.62      0.64      0.63        50\n",
            "   n04486054       0.91      0.84      0.87        50\n",
            "   n04487081       0.80      0.86      0.83        50\n",
            "   n04501370       0.50      0.52      0.51        50\n",
            "   n04507155       0.21      0.50      0.29        50\n",
            "   n04532106       0.41      0.34      0.37        50\n",
            "   n04532670       0.75      0.66      0.70        50\n",
            "   n04540053       0.70      0.66      0.68        50\n",
            "   n04560804       0.45      0.28      0.35        50\n",
            "   n04562935       0.74      0.80      0.77        50\n",
            "   n04596742       0.57      0.54      0.56        50\n",
            "   n04597913       0.42      0.22      0.29        50\n",
            "   n06596364       0.39      0.82      0.53        50\n",
            "   n07579787       0.54      0.42      0.47        50\n",
            "   n07583066       0.68      0.56      0.62        50\n",
            "   n07614500       0.50      0.32      0.39        50\n",
            "   n07615774       0.58      0.44      0.50        50\n",
            "   n07695742       0.70      0.46      0.55        50\n",
            "   n07711569       0.67      0.28      0.39        50\n",
            "   n07715103       0.74      0.56      0.64        50\n",
            "   n07720875       0.95      0.70      0.80        50\n",
            "   n07734744       0.51      0.80      0.62        50\n",
            "   n07747607       0.78      0.62      0.69        50\n",
            "   n07749582       0.59      0.74      0.65        50\n",
            "   n07753592       0.74      0.62      0.67        50\n",
            "   n07768694       0.75      0.72      0.73        50\n",
            "   n07871810       0.50      0.56      0.53        50\n",
            "   n07873807       0.71      0.72      0.71        50\n",
            "   n07875152       0.72      0.58      0.64        50\n",
            "   n07920052       0.85      0.78      0.81        50\n",
            "   n09193705       0.67      0.72      0.69        50\n",
            "   n09246464       0.49      0.40      0.44        50\n",
            "   n09256479       0.61      0.62      0.61        50\n",
            "   n09332890       0.45      0.42      0.43        50\n",
            "   n09428293       0.54      0.60      0.57        50\n",
            "   n12267677       0.59      0.54      0.56        50\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.61      0.57      0.58     10000\n",
            "weighted avg       0.61      0.57      0.58     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the classification report, let’s assume identified classes with an F1-score lower than 0.50."
      ],
      "metadata": {
        "id": "yCslpgL5Ar3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume we have true_labels and predicted_labels from previous steps:"
      ],
      "metadata": {
        "id": "AjzEXsscDL6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report_dict = classification_report(true_labels, predicted_labels, target_names=list(class_indices.keys()), output_dict=True)"
      ],
      "metadata": {
        "id": "rMVadf0ZDNYG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify Poor Performing Classes:"
      ],
      "metadata": {
        "id": "Cdl4tJT5DTUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_poor_performing_classes(report_dict, threshold=0.5):\n",
        "    low_accuracy_classes = []\n",
        "    for class_name, metrics in report_dict.items():\n",
        "        if class_name not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
        "            if metrics[\"f1-score\"] < threshold:\n",
        "                low_accuracy_classes.append(class_name)\n",
        "    return low_accuracy_classes\n",
        "\n",
        "# Define the threshold for F1-score\n",
        "f1_threshold = 0.5\n",
        "\n",
        "# Get the list of poor performing classes\n",
        "low_accuracy_classes = get_poor_performing_classes(report_dict, f1_threshold)\n",
        "print(f\"Poor performing classes: {low_accuracy_classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAn6E9seDT5P",
        "outputId": "d01f4fb3-28f5-4319-bb8b-f1bc718ce0e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poor performing classes: ['n01644900', 'n01742172', 'n01770393', 'n02085620', 'n02099601', 'n02099712', 'n02113799', 'n02124075', 'n02231487', 'n02233338', 'n02236044', 'n02395406', 'n02403003', 'n02730930', 'n02788148', 'n02791270', 'n02795169', 'n02883205', 'n02906734', 'n02909870', 'n02948072', 'n02950826', 'n02977058', 'n02999410', 'n03160309', 'n03250847', 'n03255030', 'n03400231', 'n03404251', 'n03617480', 'n03637318', 'n03763968', 'n03770439', 'n03804744', 'n03838899', 'n03902125', 'n03970156', 'n03976657', 'n03983396', 'n04008634', 'n04023962', 'n04067472', 'n04133789', 'n04259630', 'n04265275', 'n04275548', 'n04366367', 'n04371430', 'n04376876', 'n04398044', 'n04507155', 'n04532106', 'n04560804', 'n04597913', 'n07579787', 'n07614500', 'n07711569', 'n09246464', 'n09332890']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make an additional augmentation:"
      ],
      "metadata": {
        "id": "98Qs8Z8lnxrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "additional_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    width_shift_range=0.4,\n",
        "    height_shift_range=0.4,\n",
        "    shear_range=0.4,\n",
        "    zoom_range=0.4,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "j4RCSaiXn0_o"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "train_dir = '/content/tiny-imagenet-200/train'\n",
        "\n",
        "for class_name in low_accuracy_classes:\n",
        "    class_dir = os.path.join(train_dir, class_name, 'images')\n",
        "    if os.path.exists(class_dir):\n",
        "        for file_name in os.listdir(class_dir):\n",
        "            full_file_name = os.path.join(class_dir, file_name)\n",
        "            if os.path.isfile(full_file_name):\n",
        "                shutil.move(full_file_name, os.path.join(train_dir, class_name))\n",
        "        print(f\"Moved files from {class_dir} to {os.path.join(train_dir, class_name)}\")\n",
        "    else:\n",
        "        print(f\"Directory {class_dir} does not exist.\")\n"
      ],
      "metadata": {
        "id": "NuJ1_Xw3G7as",
        "outputId": "f5bac622-5e4c-4908-fe4a-467f8118a8a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved files from /content/tiny-imagenet-200/train/n01644900/images to /content/tiny-imagenet-200/train/n01644900\n",
            "Moved files from /content/tiny-imagenet-200/train/n01742172/images to /content/tiny-imagenet-200/train/n01742172\n",
            "Moved files from /content/tiny-imagenet-200/train/n01770393/images to /content/tiny-imagenet-200/train/n01770393\n",
            "Moved files from /content/tiny-imagenet-200/train/n02085620/images to /content/tiny-imagenet-200/train/n02085620\n",
            "Moved files from /content/tiny-imagenet-200/train/n02099601/images to /content/tiny-imagenet-200/train/n02099601\n",
            "Moved files from /content/tiny-imagenet-200/train/n02099712/images to /content/tiny-imagenet-200/train/n02099712\n",
            "Moved files from /content/tiny-imagenet-200/train/n02113799/images to /content/tiny-imagenet-200/train/n02113799\n",
            "Moved files from /content/tiny-imagenet-200/train/n02124075/images to /content/tiny-imagenet-200/train/n02124075\n",
            "Moved files from /content/tiny-imagenet-200/train/n02231487/images to /content/tiny-imagenet-200/train/n02231487\n",
            "Moved files from /content/tiny-imagenet-200/train/n02233338/images to /content/tiny-imagenet-200/train/n02233338\n",
            "Moved files from /content/tiny-imagenet-200/train/n02236044/images to /content/tiny-imagenet-200/train/n02236044\n",
            "Moved files from /content/tiny-imagenet-200/train/n02395406/images to /content/tiny-imagenet-200/train/n02395406\n",
            "Moved files from /content/tiny-imagenet-200/train/n02403003/images to /content/tiny-imagenet-200/train/n02403003\n",
            "Moved files from /content/tiny-imagenet-200/train/n02730930/images to /content/tiny-imagenet-200/train/n02730930\n",
            "Moved files from /content/tiny-imagenet-200/train/n02788148/images to /content/tiny-imagenet-200/train/n02788148\n",
            "Moved files from /content/tiny-imagenet-200/train/n02791270/images to /content/tiny-imagenet-200/train/n02791270\n",
            "Moved files from /content/tiny-imagenet-200/train/n02795169/images to /content/tiny-imagenet-200/train/n02795169\n",
            "Moved files from /content/tiny-imagenet-200/train/n02883205/images to /content/tiny-imagenet-200/train/n02883205\n",
            "Moved files from /content/tiny-imagenet-200/train/n02906734/images to /content/tiny-imagenet-200/train/n02906734\n",
            "Moved files from /content/tiny-imagenet-200/train/n02909870/images to /content/tiny-imagenet-200/train/n02909870\n",
            "Moved files from /content/tiny-imagenet-200/train/n02948072/images to /content/tiny-imagenet-200/train/n02948072\n",
            "Moved files from /content/tiny-imagenet-200/train/n02950826/images to /content/tiny-imagenet-200/train/n02950826\n",
            "Moved files from /content/tiny-imagenet-200/train/n02977058/images to /content/tiny-imagenet-200/train/n02977058\n",
            "Moved files from /content/tiny-imagenet-200/train/n02999410/images to /content/tiny-imagenet-200/train/n02999410\n",
            "Moved files from /content/tiny-imagenet-200/train/n03160309/images to /content/tiny-imagenet-200/train/n03160309\n",
            "Moved files from /content/tiny-imagenet-200/train/n03250847/images to /content/tiny-imagenet-200/train/n03250847\n",
            "Moved files from /content/tiny-imagenet-200/train/n03255030/images to /content/tiny-imagenet-200/train/n03255030\n",
            "Moved files from /content/tiny-imagenet-200/train/n03400231/images to /content/tiny-imagenet-200/train/n03400231\n",
            "Moved files from /content/tiny-imagenet-200/train/n03404251/images to /content/tiny-imagenet-200/train/n03404251\n",
            "Moved files from /content/tiny-imagenet-200/train/n03617480/images to /content/tiny-imagenet-200/train/n03617480\n",
            "Moved files from /content/tiny-imagenet-200/train/n03637318/images to /content/tiny-imagenet-200/train/n03637318\n",
            "Moved files from /content/tiny-imagenet-200/train/n03763968/images to /content/tiny-imagenet-200/train/n03763968\n",
            "Moved files from /content/tiny-imagenet-200/train/n03770439/images to /content/tiny-imagenet-200/train/n03770439\n",
            "Moved files from /content/tiny-imagenet-200/train/n03804744/images to /content/tiny-imagenet-200/train/n03804744\n",
            "Moved files from /content/tiny-imagenet-200/train/n03838899/images to /content/tiny-imagenet-200/train/n03838899\n",
            "Moved files from /content/tiny-imagenet-200/train/n03902125/images to /content/tiny-imagenet-200/train/n03902125\n",
            "Moved files from /content/tiny-imagenet-200/train/n03970156/images to /content/tiny-imagenet-200/train/n03970156\n",
            "Moved files from /content/tiny-imagenet-200/train/n03976657/images to /content/tiny-imagenet-200/train/n03976657\n",
            "Moved files from /content/tiny-imagenet-200/train/n03983396/images to /content/tiny-imagenet-200/train/n03983396\n",
            "Moved files from /content/tiny-imagenet-200/train/n04008634/images to /content/tiny-imagenet-200/train/n04008634\n",
            "Moved files from /content/tiny-imagenet-200/train/n04023962/images to /content/tiny-imagenet-200/train/n04023962\n",
            "Moved files from /content/tiny-imagenet-200/train/n04067472/images to /content/tiny-imagenet-200/train/n04067472\n",
            "Moved files from /content/tiny-imagenet-200/train/n04133789/images to /content/tiny-imagenet-200/train/n04133789\n",
            "Moved files from /content/tiny-imagenet-200/train/n04259630/images to /content/tiny-imagenet-200/train/n04259630\n",
            "Moved files from /content/tiny-imagenet-200/train/n04265275/images to /content/tiny-imagenet-200/train/n04265275\n",
            "Moved files from /content/tiny-imagenet-200/train/n04275548/images to /content/tiny-imagenet-200/train/n04275548\n",
            "Moved files from /content/tiny-imagenet-200/train/n04366367/images to /content/tiny-imagenet-200/train/n04366367\n",
            "Moved files from /content/tiny-imagenet-200/train/n04371430/images to /content/tiny-imagenet-200/train/n04371430\n",
            "Moved files from /content/tiny-imagenet-200/train/n04376876/images to /content/tiny-imagenet-200/train/n04376876\n",
            "Moved files from /content/tiny-imagenet-200/train/n04398044/images to /content/tiny-imagenet-200/train/n04398044\n",
            "Moved files from /content/tiny-imagenet-200/train/n04507155/images to /content/tiny-imagenet-200/train/n04507155\n",
            "Moved files from /content/tiny-imagenet-200/train/n04532106/images to /content/tiny-imagenet-200/train/n04532106\n",
            "Moved files from /content/tiny-imagenet-200/train/n04560804/images to /content/tiny-imagenet-200/train/n04560804\n",
            "Moved files from /content/tiny-imagenet-200/train/n04597913/images to /content/tiny-imagenet-200/train/n04597913\n",
            "Moved files from /content/tiny-imagenet-200/train/n07579787/images to /content/tiny-imagenet-200/train/n07579787\n",
            "Moved files from /content/tiny-imagenet-200/train/n07614500/images to /content/tiny-imagenet-200/train/n07614500\n",
            "Moved files from /content/tiny-imagenet-200/train/n07711569/images to /content/tiny-imagenet-200/train/n07711569\n",
            "Moved files from /content/tiny-imagenet-200/train/n09246464/images to /content/tiny-imagenet-200/train/n09246464\n",
            "Moved files from /content/tiny-imagenet-200/train/n09332890/images to /content/tiny-imagenet-200/train/n09332890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an additional generator for training images only with classes with low accuracy:"
      ],
      "metadata": {
        "id": "qTlp2PvJn6Pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils import Sequence\n",
        "\n",
        "# Функція для створення генератора для класів з низькою точністю\n",
        "def create_class_specific_generator(generator, class_indices, classes, base_dirs):\n",
        "    class_filenames = []\n",
        "    class_labels = []\n",
        "    for base_dir in base_dirs:\n",
        "        for class_name in classes:\n",
        "            class_index = class_indices[class_name]\n",
        "            class_dir = os.path.join(base_dir, class_name)\n",
        "            if not os.path.exists(class_dir):\n",
        "                print(f\"Directory {class_dir} does not exist.\")\n",
        "                continue\n",
        "            class_files = [os.path.join(class_dir, fname) for fname in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, fname)) and fname.lower().endswith(('.jpeg', '.jpg', '.png'))]\n",
        "            if not class_files:\n",
        "                print(f\"No files found in directory {class_dir}.\")\n",
        "                continue\n",
        "            class_filenames.extend(class_files)\n",
        "            class_labels.extend([class_name] * len(class_files))\n",
        "            print(f\"Found {len(class_files)} files in directory {class_dir}.\")\n",
        "\n",
        "    print(f\"Found {len(class_filenames)} images for augmentation.\")\n",
        "\n",
        "    if not class_filenames:\n",
        "        print(\"No valid images found for augmentation.\")\n",
        "        return None\n",
        "\n",
        "    # Додавання dummy-класів для вирівнювання кількості класів\n",
        "    all_class_names = list(class_indices.keys())\n",
        "    for class_name in all_class_names:\n",
        "        if class_name not in classes:\n",
        "            dummy_image = class_filenames[0]  # Використовуємо перше зображення як dummy\n",
        "            class_filenames.append(dummy_image)\n",
        "            class_labels.append(class_name)\n",
        "\n",
        "    df = pd.DataFrame({'filename': class_filenames, 'class': class_labels})\n",
        "    print(df.head())  # Перевірка DataFrame\n",
        "\n",
        "    class_specific_generator = generator.flow_from_dataframe(\n",
        "        dataframe=df,\n",
        "        directory=None,  # Використання абсолютних шляхів\n",
        "        x_col='filename',\n",
        "        y_col='class',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "    return class_specific_generator\n",
        "\n",
        "# Переконайтеся, що train_dir і val_dir визначені правильно\n",
        "train_dir = '/content/tiny-imagenet-200/train'\n",
        "val_dir = '/content/tiny-imagenet-200/val'\n",
        "\n",
        "# Створення нових екземплярів генераторів після переміщення файлів\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Створення генератора для класів з низькою точністю\n",
        "additional_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "class_indices = {class_name: idx for idx, class_name in enumerate(os.listdir(train_dir))}\n",
        "additional_generator = create_class_specific_generator(additional_datagen, class_indices, low_accuracy_classes, [train_dir, val_dir])\n",
        "\n",
        "if additional_generator is not None:\n",
        "    class CombinedGenerator(Sequence):\n",
        "        def __init__(self, generator1, generator2):\n",
        "            self.generator1 = generator1\n",
        "            self.generator2 = generator2\n",
        "\n",
        "        def __len__(self):\n",
        "            return min(len(self.generator1), len(self.generator2))\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            x1, y1 = self.generator1[index]\n",
        "            x2, y2 = self.generator2[index]\n",
        "            x_combined = np.concatenate((x1, x2), axis=0)\n",
        "            y_combined = np.concatenate((y1, y2), axis=0)\n",
        "            return x_combined, y_combined\n",
        "\n",
        "    # Об'єднання основного і додаткового генераторів\n",
        "    combined_generator = CombinedGenerator(train_generator, additional_generator)\n",
        "\n",
        "    # Донавчання моделі з використанням об'єднаного генератора\n",
        "    history = model.fit(\n",
        "        combined_generator,\n",
        "        epochs=30,\n",
        "        validation_data=val_generator,\n",
        "        callbacks=[early_stopping, reduce_lr, lr_scheduler]\n",
        "    )\n",
        "else:\n",
        "    print(\"Additional generator is None. Skipping training with augmented data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dVeg1xCn7Do",
        "outputId": "536aacfa-1a0a-42ee-a0a4-39c88d5c1aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n01644900.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n01742172.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n01770393.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02085620.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02099601.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02099712.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02113799.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02124075.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02231487.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02233338.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02236044.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02395406.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02403003.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02730930.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02788148.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02791270.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02795169.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02883205.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02906734.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02909870.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02948072.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02950826.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02977058.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n02999410.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03160309.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03250847.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03255030.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03400231.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03404251.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03617480.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03637318.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03763968.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03770439.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03804744.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03838899.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03902125.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03970156.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03976657.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n03983396.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04008634.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04023962.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04067472.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04133789.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04259630.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04265275.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04275548.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04366367.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04371430.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04376876.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04398044.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04507155.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04532106.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04560804.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n04597913.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n07579787.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n07614500.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n07711569.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n09246464.\n",
            "Found 500 files in directory /content/tiny-imagenet-200/train/n09332890.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n01644900.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n01742172.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n01770393.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02085620.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02099601.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02099712.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02113799.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02124075.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02231487.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02233338.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02236044.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02395406.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02403003.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02730930.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02788148.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02791270.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02795169.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02883205.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02906734.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02909870.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02948072.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02950826.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02977058.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n02999410.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03160309.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03250847.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03255030.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03400231.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03404251.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03617480.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03637318.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03763968.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03770439.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03804744.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03838899.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03902125.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03970156.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03976657.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n03983396.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04008634.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04023962.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04067472.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04133789.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04259630.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04265275.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04275548.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04366367.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04371430.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04376876.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04398044.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04507155.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04532106.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04560804.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n04597913.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n07579787.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n07614500.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n07711569.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n09246464.\n",
            "Found 50 files in directory /content/tiny-imagenet-200/val/n09332890.\n",
            "Found 32450 images for augmentation.\n",
            "                                            filename      class\n",
            "0  /content/tiny-imagenet-200/train/n01644900/n01...  n01644900\n",
            "1  /content/tiny-imagenet-200/train/n01644900/n01...  n01644900\n",
            "2  /content/tiny-imagenet-200/train/n01644900/n01...  n01644900\n",
            "3  /content/tiny-imagenet-200/train/n01644900/n01...  n01644900\n",
            "4  /content/tiny-imagenet-200/train/n01644900/n01...  n01644900\n",
            "Found 32591 validated image filenames belonging to 200 classes.\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1019/1019\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 155ms/step - accuracy: 0.6927 - loss: 1.3445 - val_accuracy: 0.6620 - val_loss: 1.5343 - learning_rate: 3.6788e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m1019/1019\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 90ms/step - accuracy: 0.7823 - loss: 0.9539 - val_accuracy: 0.6857 - val_loss: 1.4401 - learning_rate: 3.6788e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m 889/1019\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.8359 - loss: 0.7465"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "2ITcrt1OD6XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "id": "GrUtIxWOFiYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D8G3XDqAM41N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/Korniev/Machine-Learning-projects/blob/main/ClassReport_augm_image_classification_tiny_imagenet.ipynb",
      "authorship_tag": "ABX9TyMvqKRBV3/FI6XFH9zHvkRA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}